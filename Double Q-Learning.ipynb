{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym\n",
    "!pip install numpy \n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2df5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample()) #random action \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b023b",
   "metadata": {},
   "source": [
    "Step returns: observation, reward, done (whether it's time to reset the environment), info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16b6c0",
   "metadata": {},
   "source": [
    "Rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a9c17c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0100677  -0.03361977 -0.01100441 -0.03403921]\n",
      "[-0.0107401   0.16165826 -0.0116852  -0.33017373]\n",
      "[-0.00750693 -0.03329543 -0.01828867 -0.04119854]\n",
      "[-0.00817284 -0.22815041 -0.01911264  0.24565849]\n",
      "[-0.01273585 -0.42299426 -0.01419947  0.5322521 ]\n",
      "[-0.02119573 -0.22767548 -0.00355443  0.23512897]\n",
      "[-0.02574924 -0.42274648  0.00114815  0.52668864]\n",
      "[-0.03420417 -0.2276407   0.01168192  0.23436768]\n",
      "[-0.03875699 -0.4229276   0.01636928  0.5307124 ]\n",
      "[-0.04721554 -0.61827594  0.02698352  0.8285081 ]\n",
      "[-0.05958106 -0.42353308  0.04355368  0.54443234]\n",
      "[-0.06805172 -0.61923915  0.05444233  0.85051376]\n",
      "[-0.08043651 -0.8150595   0.0714526   1.1598072 ]\n",
      "[-0.09673769 -1.0110359   0.09464875  1.474011  ]\n",
      "[-0.11695841 -0.81718963  0.12412897  1.2123282 ]\n",
      "[-0.1333022  -0.62386894  0.14837553  0.96097857]\n",
      "[-0.14577958 -0.8206399   0.1675951   1.2963545 ]\n",
      "[-0.16219237 -1.0174464   0.1935222   1.6364707 ]\n",
      "Episode finished after 18 timesteps\n",
      "[-0.01582736  0.04277249  0.02851858  0.02398545]\n",
      "[-0.01497191  0.2374741   0.02899829 -0.25956488]\n",
      "[-0.01022243  0.43217033  0.023807   -0.54296213]\n",
      "[-0.00157902  0.6269497   0.01294775 -0.8280499 ]\n",
      "[ 0.01095997  0.8218923  -0.00361324 -1.1166327 ]\n",
      "[ 0.02739782  1.0170615  -0.0259459  -1.4104469 ]\n",
      "[ 0.04773905  0.8222707  -0.05415484 -1.1259862 ]\n",
      "[ 0.06418446  0.62789863 -0.07667456 -0.8507693 ]\n",
      "[ 0.07674244  0.4339012  -0.09368995 -0.58314836]\n",
      "[ 0.08542046  0.6302022  -0.10535292 -0.90381306]\n",
      "[ 0.0980245   0.4366528  -0.12342917 -0.64601517]\n",
      "[ 0.10675756  0.6332588  -0.13634947 -0.97487664]\n",
      "[ 0.11942273  0.8299202  -0.15584701 -1.3070935 ]\n",
      "[ 0.13602114  1.0266356  -0.18198888 -1.6442243 ]\n",
      "Episode finished after 14 timesteps\n",
      "[-0.04894793 -0.00410055 -0.0168098  -0.0273559 ]\n",
      "[-0.04902994  0.19125839 -0.01735692 -0.32529473]\n",
      "[-0.04520477 -0.00361219 -0.02386281 -0.03813559]\n",
      "[-0.04527701 -0.19838396 -0.02462553  0.2469239 ]\n",
      "[-0.04924469 -0.00291913 -0.01968705 -0.05342364]\n",
      "[-0.04930308  0.19247949 -0.02075552 -0.3522524 ]\n",
      "[-0.04545349  0.38789037 -0.02780057 -0.65140724]\n",
      "[-0.03769568  0.1931664  -0.04082872 -0.3676065 ]\n",
      "[-0.03383235  0.388844   -0.04818084 -0.6728786 ]\n",
      "[-0.02605547  0.5846014  -0.06163841 -0.98033357]\n",
      "[-0.01436344  0.78049296 -0.08124509 -1.2917231 ]\n",
      "[ 0.00124641  0.5864924  -0.10707955 -1.025542  ]\n",
      "[ 0.01297626  0.7828646  -0.12759039 -1.3498344 ]\n",
      "[ 0.02863355  0.9793376  -0.15458708 -1.6795583 ]\n",
      "[ 0.04822031  0.7863086  -0.18817824 -1.4387352 ]\n",
      "Episode finished after 15 timesteps\n",
      "[ 0.04545416  0.04625627  0.02657373 -0.01129781]\n",
      "[ 0.04637928  0.24098724  0.02634777 -0.2954794 ]\n",
      "[ 0.05119903  0.43572384  0.02043818 -0.57973754]\n",
      "[ 0.0599135   0.24032155  0.00884343 -0.28068691]\n",
      "[0.06471994 0.04507457 0.0032297  0.01477203]\n",
      "[ 0.06562143  0.24015005  0.00352514 -0.27689013]\n",
      "[ 0.07042443  0.04497799 -0.00201267  0.01690253]\n",
      "[ 0.07132399  0.24012874 -0.00167462 -0.27641475]\n",
      "[ 0.07612656  0.43527454 -0.00720291 -0.5696254 ]\n",
      "[ 0.08483206  0.24025436 -0.01859542 -0.2792203 ]\n",
      "[ 0.08963714  0.04540254 -0.02417982  0.00754015]\n",
      "[ 0.09054519 -0.14936444 -0.02402902  0.29249704]\n",
      "[ 0.0875579   0.04609173 -0.01817908 -0.00766642]\n",
      "[ 0.08847973 -0.14876486 -0.01833241  0.2792258 ]\n",
      "[ 0.08550444  0.04661375 -0.01274789 -0.01918229]\n",
      "[ 0.08643672  0.24191618 -0.01313154 -0.3158599 ]\n",
      "[ 0.09127504  0.04698371 -0.01944874 -0.02734698]\n",
      "[ 0.09221471  0.2423791  -0.01999568 -0.3261022 ]\n",
      "[ 0.0970623   0.43777993 -0.02651772 -0.6250232 ]\n",
      "[ 0.10581789  0.63326186 -0.03901818 -0.9259383 ]\n",
      "[ 0.11848313  0.8288884  -0.05753695 -1.2306232 ]\n",
      "[ 0.1350609   0.6345519  -0.08214942 -0.9565073 ]\n",
      "[ 0.14775194  0.44062507 -0.10127956 -0.6907229 ]\n",
      "[ 0.15656444  0.6369957  -0.11509402 -1.0134946 ]\n",
      "[ 0.16930436  0.44358134 -0.1353639  -0.7590556 ]\n",
      "[ 0.17817599  0.25055844 -0.15054502 -0.5118454 ]\n",
      "[ 0.18318714  0.0578419  -0.16078193 -0.2701334 ]\n",
      "[ 0.18434398 -0.13466413 -0.1661846  -0.03216515]\n",
      "[ 0.1816507  -0.32706133 -0.1668279   0.203821  ]\n",
      "[ 0.17510948 -0.5194534  -0.16275148  0.43958232]\n",
      "[ 0.1647204  -0.71194303 -0.15395984  0.6768632 ]\n",
      "[ 0.15048155 -0.9046287  -0.14042257  0.9173873 ]\n",
      "[ 0.13238898 -1.0976014  -0.12207483  1.1628486 ]\n",
      "[ 0.11043695 -1.2909409  -0.09881786  1.4148986 ]\n",
      "[ 0.08461813 -1.4847095  -0.07051988  1.6751285 ]\n",
      "[ 0.05492393 -1.6789458  -0.03701731  1.9450431 ]\n",
      "[ 0.02134502 -1.4834497   0.00188355  1.6411191 ]\n",
      "[-0.00832397 -1.6785936   0.03470593  1.9343883 ]\n",
      "[-0.04189585 -1.874069    0.0733937   2.2376263 ]\n",
      "[-0.07937723 -2.0698047   0.11814623  2.5519977 ]\n",
      "[-0.12077332 -1.8758096   0.16918617  2.2976878 ]\n",
      "Episode finished after 41 timesteps\n",
      "[-0.00647405 -0.01746647  0.02269964 -0.02142745]\n",
      "[-0.00682338  0.17732272  0.0222711  -0.30686283]\n",
      "[-0.00327692  0.37212035  0.01613384 -0.59243965]\n",
      "[ 0.00416549  0.1767763   0.00428505 -0.29471856]\n",
      "[ 0.00770101  0.3718369  -0.00160932 -0.586047  ]\n",
      "[ 0.01513775  0.5669814  -0.01333026 -0.8792364 ]\n",
      "[ 0.02647738  0.7622819  -0.03091499 -1.1760801 ]\n",
      "[ 0.04172301  0.9577915  -0.05443659 -1.4782921 ]\n",
      "[ 0.06087884  0.76337487 -0.08400244 -1.2030954 ]\n",
      "[ 0.07614634  0.5694334  -0.10806435 -0.93787676]\n",
      "[ 0.08753501  0.7658334  -0.12682188 -1.2624674 ]\n",
      "[ 0.10285167  0.962328   -0.15207122 -1.592028  ]\n",
      "[ 0.12209824  0.769303   -0.18391179 -1.3503687 ]\n",
      "Episode finished after 13 timesteps\n",
      "[-0.04780674 -0.02305552  0.00958571 -0.01839813]\n",
      "[-0.04826785  0.17192766  0.00921775 -0.3080413 ]\n",
      "[-0.0448293   0.36691707  0.00305692 -0.597803  ]\n",
      "[-0.03749096  0.5619961  -0.00889914 -0.8895215 ]\n",
      "[-0.02625104  0.7572377  -0.02668957 -1.1849885 ]\n",
      "[-0.01110628  0.9526955  -0.05038934 -1.4859166 ]\n",
      "[ 0.00794763  0.7582226  -0.08010767 -1.2093858 ]\n",
      "[ 0.02311208  0.56422126 -0.10429539 -0.94284344]\n",
      "[ 0.0343965   0.37064746 -0.12315226 -0.6846678 ]\n",
      "[ 0.04180945  0.17743105 -0.1368456  -0.43315354]\n",
      "[ 0.04535807  0.37419826 -0.14550868 -0.7656522 ]\n",
      "[ 0.05284204  0.570992   -0.16082172 -1.100352  ]\n",
      "[ 0.06426188  0.37830928 -0.18282877 -0.8621356 ]\n",
      "[ 0.07182806  0.1860844  -0.20007148 -0.6320566 ]\n",
      "Episode finished after 14 timesteps\n",
      "[ 0.03128926 -0.0230001   0.01957234  0.02433307]\n",
      "[ 0.03082925  0.17183578  0.020059   -0.26211086]\n",
      "[ 0.03426597  0.36666575  0.01481678 -0.54840004]\n",
      "[ 0.04159928  0.17133881  0.00384878 -0.25108585]\n",
      "[ 0.04502606  0.36640558 -0.00117294 -0.54255235]\n",
      "[ 0.05235417  0.17130014 -0.01202398 -0.2502392 ]\n",
      "[ 0.05578018  0.36659172 -0.01702877 -0.54669034]\n",
      "[ 0.06311201  0.17171311 -0.02796257 -0.25942102]\n",
      "[ 0.06654627 -0.02299873 -0.033151    0.02431262]\n",
      "[ 0.0660863   0.17258257 -0.03266474 -0.27864274]\n",
      "[ 0.06953795  0.3681549  -0.0382376  -0.58144647]\n",
      "[ 0.07690105  0.173589   -0.04986653 -0.30105007]\n",
      "[ 0.08037283  0.3693849  -0.05588753 -0.6090336 ]\n",
      "[ 0.08776052  0.17508696 -0.0680682  -0.33446404]\n",
      "[ 0.09126227 -0.01900353 -0.07475748 -0.06399909]\n",
      "[ 0.0908822   0.17710622 -0.07603747 -0.37930033]\n",
      "[ 0.09442432 -0.0168582  -0.08362347 -0.11152786]\n",
      "[ 0.09408715  0.17935626 -0.08585402 -0.42937773]\n",
      "[ 0.09767428  0.37558246 -0.09444159 -0.747843  ]\n",
      "[ 0.10518593  0.57187164 -0.10939844 -1.0686892 ]\n",
      "[ 0.11662336  0.37835327 -0.13077223 -0.812246  ]\n",
      "[ 0.12419043  0.1852418  -0.14701715 -0.56338966]\n",
      "[ 0.12789527  0.3820875  -0.15828495 -0.8985405 ]\n",
      "[ 0.13553701  0.18942396 -0.17625575 -0.6594996 ]\n",
      "[ 0.13932548  0.38650388 -0.18944575 -1.0020908 ]\n",
      "Episode finished after 25 timesteps\n",
      "[ 0.02654007 -0.02147644  0.0302482   0.012113  ]\n",
      "[ 0.02611054  0.17319895  0.03049046 -0.2708749 ]\n",
      "[ 0.02957452 -0.02234453  0.02507297  0.03126681]\n",
      "[ 0.02912763  0.17240906  0.0256983  -0.25340107]\n",
      "[ 0.03257581  0.36715484  0.02063028 -0.5378688 ]\n",
      "[ 0.03991891  0.171749    0.0098729  -0.23875755]\n",
      "[ 0.04335389 -0.0235126   0.00509775  0.05702315]\n",
      "[ 0.04288364  0.1715359   0.00623822 -0.23404706]\n",
      "[ 0.04631435  0.36656815  0.00155728 -0.5247557 ]\n",
      "[ 0.05364572  0.17142433 -0.00893784 -0.23158251]\n",
      "[ 0.0570742   0.36667284 -0.01356949 -0.5270713 ]\n",
      "[ 0.06440766  0.56198305 -0.02411092 -0.8239989 ]\n",
      "[ 0.07564732  0.7574264  -0.04059089 -1.1241666 ]\n",
      "[ 0.09079585  0.56285936 -0.06307422 -0.8444869 ]\n",
      "[ 0.10205304  0.36865216 -0.07996397 -0.57228696]\n",
      "[ 0.10942608  0.17473716 -0.09140971 -0.30582824]\n",
      "[ 0.11292082  0.37103474 -0.09752627 -0.6258824 ]\n",
      "[ 0.12034152  0.17739974 -0.11004391 -0.36543736]\n",
      "[ 0.12388951 -0.01600037 -0.11735266 -0.1093796 ]\n",
      "[ 0.1235695  -0.20926224 -0.11954026  0.14409679]\n",
      "[ 0.11938426 -0.0126492  -0.11665832 -0.18377928]\n",
      "[ 0.11913127  0.18393196 -0.1203339  -0.51086664]\n",
      "[ 0.12280992  0.3805252  -0.13055123 -0.8389169 ]\n",
      "[ 0.13042042  0.18740444 -0.14732957 -0.589974  ]\n",
      "[ 0.1341685   0.38424864 -0.15912905 -0.92519987]\n",
      "[ 0.14185348  0.19159213 -0.17763305 -0.686453  ]\n",
      "[ 0.14568533  0.38867685 -0.19136211 -1.0293782 ]\n",
      "Episode finished after 27 timesteps\n",
      "[ 0.02383152  0.00310906 -0.00174937 -0.03578124]\n",
      "[ 0.0238937  -0.19198777 -0.00246499  0.25634924]\n",
      "[ 0.02005395 -0.38707444  0.00266199  0.54825366]\n",
      "[ 0.01231246 -0.58223367  0.01362707  0.8417741 ]\n",
      "[ 0.00066779 -0.38730037  0.03046255  0.5534075 ]\n",
      "[-0.00707822 -0.58283657  0.0415307   0.8555303 ]\n",
      "[-0.01873495 -0.7784991   0.0586413   1.1609776 ]\n",
      "[-0.03430493 -0.9743338   0.08186086  1.4714555 ]\n",
      "[-0.05379161 -0.7803029   0.11128996  1.2054238 ]\n",
      "[-0.06939767 -0.97667307  0.13539843  1.5308087 ]\n",
      "[-0.08893113 -1.1731427   0.16601461  1.8625014 ]\n",
      "[-0.11239398 -0.9801844   0.20326464  1.6256278 ]\n",
      "Episode finished after 12 timesteps\n",
      "[-0.01094302 -0.03970848  0.04430192  0.04406135]\n",
      "[-0.01173719  0.15475112  0.04518314 -0.23432136]\n",
      "[-0.00864216 -0.0409863   0.04049671  0.07226446]\n",
      "[-0.00946189 -0.23666473  0.041942    0.3774442 ]\n",
      "[-0.01419519 -0.04216277  0.04949089  0.09827521]\n",
      "[-0.01503844 -0.2379578   0.0514564   0.40615255]\n",
      "[-0.0197976  -0.04360186  0.05957944  0.13012598]\n",
      "[-0.02066963  0.15061826  0.06218196 -0.14318126]\n",
      "[-0.01765727  0.3447971   0.05931834 -0.4156169 ]\n",
      "[-0.01076133  0.1488868   0.051006   -0.10483893]\n",
      "[-0.00778359 -0.04692759  0.04890922  0.20348993]\n",
      "[-0.00872214  0.14746203  0.05297902 -0.07337224]\n",
      "[-0.0057729   0.341786    0.05151158 -0.34888068]\n",
      "[ 0.00106282  0.14597072  0.04453396 -0.04040964]\n",
      "[ 0.00398223 -0.04976062  0.04372577  0.26598492]\n",
      "[ 0.00298702  0.14471087  0.04904547 -0.0125922 ]\n",
      "[ 0.00588124  0.33909637  0.04879363 -0.28940627]\n",
      "[ 0.01266317  0.5334898   0.0430055  -0.56630975]\n",
      "[ 0.02333296  0.33779177  0.0316793  -0.2603944 ]\n",
      "[0.0300888  0.14223225 0.02647142 0.04210987]\n",
      "[ 0.03293344 -0.05325909  0.02731361  0.34302583]\n",
      "[ 0.03186826 -0.24875875  0.03417413  0.64419514]\n",
      "[ 0.02689308 -0.4443399   0.04705803  0.9474408 ]\n",
      "[ 0.01800629 -0.24988212  0.06600685  0.66990703]\n",
      "[ 0.01300865 -0.4458567   0.07940499  0.98262066]\n",
      "[ 0.00409151 -0.6419476   0.09905741  1.2991508 ]\n",
      "[-0.00874744 -0.44821283  0.12504043  1.0390484 ]\n",
      "[-0.0177117  -0.2549541   0.14582139  0.7880898 ]\n",
      "[-0.02281078 -0.45174575  0.16158319  1.1228641 ]\n",
      "[-0.0318457  -0.6485743   0.18404047  1.46156   ]\n",
      "Episode finished after 30 timesteps\n",
      "[ 0.02657243 -0.00029801  0.03010629 -0.03305541]\n",
      "[ 0.02656647 -0.19583847  0.02944518  0.26897228]\n",
      "[ 0.0226497  -0.39136797  0.03482462  0.57079506]\n",
      "[ 0.01482234 -0.58696055  0.04624053  0.87424237]\n",
      "[ 0.00308313 -0.7826797   0.06372537  1.181097  ]\n",
      "[-0.01257046 -0.5884401   0.08734731  0.9090518 ]\n",
      "[-0.02433927 -0.7846288   0.10552835  1.2278603 ]\n",
      "[-0.04003184 -0.9809387   0.13008556  1.5516548 ]\n",
      "[-0.05965062 -0.78759474  0.16111866  1.3022267 ]\n",
      "[-0.07540251 -0.59484124  0.18716319  1.0640054 ]\n",
      "[-0.08729934 -0.7918804   0.2084433   1.4091078 ]\n",
      "Episode finished after 11 timesteps\n",
      "[-0.00665081 -0.04633121 -0.00456922  0.04809486]\n",
      "[-0.00757744 -0.24138735 -0.00360733  0.33933267]\n",
      "[-0.01240518 -0.43645778  0.00317933  0.6308759 ]\n",
      "[-0.02113434 -0.24138033  0.01579685  0.3391959 ]\n",
      "[-0.02596194 -0.43672347  0.02258076  0.6368181 ]\n",
      "[-0.03469642 -0.6321529   0.03531712  0.93652576]\n",
      "[-0.04733947 -0.8277329   0.05404764  1.2400938 ]\n",
      "[-0.06389413 -1.0235056   0.07884952  1.5492064 ]\n",
      "[-0.08436424 -1.2194803   0.10983364  1.8654128 ]\n",
      "[-0.10875385 -1.025719    0.1471419   1.6087486 ]\n",
      "[-0.12926823 -0.8326106   0.17931686  1.3653196 ]\n",
      "[-0.14592044 -0.6401292   0.20662326  1.133664  ]\n",
      "Episode finished after 12 timesteps\n",
      "[0.00071722 0.02955892 0.00406121 0.02023935]\n",
      "[ 0.00130839 -0.16562104  0.004466    0.31420085]\n",
      "[-0.00200403 -0.36080632  0.01075002  0.6082889 ]\n",
      "[-0.00922015 -0.16583629  0.0229158   0.31901118]\n",
      "[-0.01253688 -0.36127698  0.02929602  0.61883193]\n",
      "[-0.01976242 -0.55679566  0.04167266  0.9205958 ]\n",
      "[-0.03089833 -0.75245523  0.06008457  1.2260786 ]\n",
      "[-0.04594744 -0.9482971   0.08460615  1.5369655 ]\n",
      "[-0.06491338 -1.1443294   0.11534546  1.8548068 ]\n",
      "[-0.08779997 -0.9506485   0.15244159  1.6000524 ]\n",
      "[-0.10681294 -0.75762546  0.18444264  1.3585199 ]\n",
      "Episode finished after 11 timesteps\n",
      "[-0.02239349  0.04914052 -0.03883307 -0.04078224]\n",
      "[-0.02141068  0.2447972  -0.03964872 -0.34546003]\n",
      "[-0.01651474  0.05026102 -0.04655792 -0.06553877]\n",
      "[-0.01550952  0.2460185  -0.0478687  -0.37253988]\n",
      "[-0.01058915  0.44178662 -0.05531949 -0.6799237 ]\n",
      "[-0.00175341  0.6376316  -0.06891797 -0.9894974 ]\n",
      "[ 0.01099922  0.44349647 -0.08870792 -0.71923184]\n",
      "[ 0.01986915  0.6397266  -0.10309255 -1.0384656 ]\n",
      "[ 0.03266368  0.44611442 -0.12386186 -0.7798448 ]\n",
      "[ 0.04158597  0.64270175 -0.13945876 -1.1087891 ]\n",
      "[ 0.05444     0.4496602  -0.16163455 -0.86290616]\n",
      "[ 0.06343321  0.25706425 -0.17889267 -0.6250917 ]\n",
      "[ 0.06857449  0.06483102 -0.1913945  -0.3936579 ]\n",
      "[ 0.06987111 -0.12713307 -0.19926766 -0.16689673]\n",
      "[ 0.06732845  0.07020044 -0.20260559 -0.51523745]\n",
      "Episode finished after 15 timesteps\n",
      "[-0.0222433   0.01914676 -0.04172369 -0.01297229]\n",
      "[-0.02186036  0.21484147 -0.04198314 -0.3185221 ]\n",
      "[-0.01756353  0.41053542 -0.04835358 -0.6241438 ]\n",
      "[-0.00935283  0.6062979  -0.06083645 -0.93165475]\n",
      "[ 0.00277313  0.8021858  -0.07946955 -1.2428178 ]\n",
      "[ 0.01881685  0.60816854 -0.10432591 -0.97604996]\n",
      "[ 0.03098022  0.8045233  -0.1238469  -1.2995968 ]\n",
      "[ 0.04707069  0.6111717  -0.14983884 -1.0481088 ]\n",
      "[ 0.05929412  0.4183211  -0.17080101 -0.8059622 ]\n",
      "[ 0.06766054  0.61532104 -0.18692026 -1.1471341 ]\n",
      "Episode finished after 10 timesteps\n",
      "[ 0.0183949  -0.03088045  0.03729047 -0.03680163]\n",
      "[ 0.01777729  0.16368745  0.03655443 -0.31748974]\n",
      "[ 0.02105104 -0.03193556  0.03020464 -0.01350663]\n",
      "[ 0.02041233 -0.22747737  0.02993451  0.28855112]\n",
      "[ 0.01586278 -0.0327948   0.03570553  0.00545751]\n",
      "[ 0.01520688  0.16179737  0.03581468 -0.2757495 ]\n",
      "[ 0.01844283  0.35639054  0.03029969 -0.5569248 ]\n",
      "[ 0.02557064  0.1608566   0.01916119 -0.2548518 ]\n",
      "[ 0.02878777 -0.03453362  0.01406416  0.04381279]\n",
      "[ 0.0280971  -0.22985439  0.01494041  0.3408997 ]\n",
      "[ 0.02350001 -0.03494816  0.02175841  0.05296531]\n",
      "[ 0.02280105  0.15985516  0.02281771 -0.23277403]\n",
      "[ 0.02599815  0.35464376  0.01816223 -0.51817304]\n",
      "[ 0.03309103  0.54950535  0.00779877 -0.80507785]\n",
      "[ 0.04408114  0.35427737 -0.00830279 -0.50995195]\n",
      "[ 0.05116668  0.15927336 -0.01850183 -0.219897  ]\n",
      "[ 0.05435215  0.35465482 -0.02289977 -0.5183583 ]\n",
      "[ 0.06144525  0.55009156 -0.03326693 -0.81816846]\n",
      "[ 0.07244708  0.3554404  -0.0496303  -0.5361319 ]\n",
      "[ 0.07955588  0.16105016 -0.06035294 -0.25949094]\n",
      "[ 0.08277689  0.35697943 -0.06554276 -0.57058275]\n",
      "[ 0.08991648  0.55295634 -0.07695441 -0.88317275]\n",
      "[ 0.1009756   0.35895908 -0.09461787 -0.6156403 ]\n",
      "[ 0.10815479  0.55526674 -0.10693067 -0.93656087]\n",
      "[ 0.11926012  0.36173666 -0.1256619  -0.67930156]\n",
      "[ 0.12649485  0.55835944 -0.13924792 -1.0087576 ]\n",
      "[ 0.13766204  0.75503767 -0.15942307 -1.3417261 ]\n",
      "[ 0.1527628   0.56224024 -0.1862576  -1.1028693 ]\n",
      "[ 0.1640076   0.759258   -0.20831499 -1.4477282 ]\n",
      "Episode finished after 29 timesteps\n",
      "[ 0.01342113  0.00182353  0.02457944 -0.01849184]\n",
      "[ 0.0134576  -0.19364214  0.02420961  0.28184372]\n",
      "[ 0.00958475 -0.3891009   0.02984648  0.5820629 ]\n",
      "[ 0.00180274 -0.19440956  0.04148774  0.29892948]\n",
      "[-0.00208545 -0.3900976   0.04746633  0.60440284]\n",
      "[-0.00988741 -0.58585006  0.05955438  0.9116507 ]\n",
      "[-0.02160441 -0.3915823   0.0777874   0.6382643 ]\n",
      "[-0.02943605 -0.19762626  0.09055269  0.37105647]\n",
      "[-0.03338858 -0.3939102   0.09797382  0.6908622 ]\n",
      "[-0.04126678 -0.20027438  0.11179106  0.43055958]\n",
      "[-0.04527227 -0.00689826  0.12040225  0.1751042 ]\n",
      "[-0.04541023  0.18631323  0.12390433 -0.07730207]\n",
      "[-0.04168397  0.3794612   0.12235829 -0.32846817]\n",
      "[-0.03409475  0.5726481   0.11578893 -0.58019835]\n",
      "[-0.02264179  0.7659734   0.10418496 -0.8342786 ]\n",
      "[-0.00732232  0.5695941   0.08749939 -0.51073194]\n",
      "[ 0.00406956  0.76338154  0.07728475 -0.774609  ]\n",
      "[ 0.01933719  0.5672863   0.06179257 -0.45864514]\n",
      "[ 0.03068292  0.37134778  0.05261967 -0.1471428 ]\n",
      "[0.03810988 0.17551333 0.04967681 0.16166535]\n",
      "[ 0.04162014 -0.0202833   0.05291012  0.46959695]\n",
      "[ 0.04121448 -0.2161112   0.06230206  0.77847606]\n",
      "[ 0.03689225 -0.41203195  0.07787158  1.090092  ]\n",
      "[ 0.02865161 -0.6080892   0.09967342  1.4061577 ]\n",
      "[ 0.01648983 -0.80429703  0.12779658  1.7282642 ]\n",
      "[ 4.0388905e-04 -1.0006272e+00  1.6236186e-01  2.0578277e+00]\n",
      "[-0.01960865 -1.1969936   0.20351842  2.3960285 ]\n",
      "Episode finished after 27 timesteps\n",
      "[-0.04233636  0.01145786 -0.00394476 -0.03794473]\n",
      "[-0.0421072   0.20663615 -0.00470365 -0.33186966]\n",
      "[-0.03797448  0.40182474 -0.01134104 -0.6260322 ]\n",
      "[-0.02993798  0.20686291 -0.02386169 -0.33694243]\n",
      "[-0.02580073  0.40231615 -0.03060053 -0.6370535 ]\n",
      "[-0.0177544   0.5978512  -0.04334161 -0.9392139 ]\n",
      "[-0.00579738  0.40333948 -0.06212588 -0.66045874]\n",
      "[ 0.00226941  0.20913456 -0.07533506 -0.38796663]\n",
      "[ 0.0064521   0.4052405  -0.08309439 -0.7034188 ]\n",
      "[ 0.01455691  0.60140973 -0.09716277 -1.021059  ]\n",
      "[ 0.02658511  0.40770718 -0.11758395 -0.76039654]\n",
      "[ 0.03473925  0.21438457 -0.13279188 -0.506905  ]\n",
      "[ 0.03902694  0.02135915 -0.14292997 -0.2588421 ]\n",
      "[ 0.03945412  0.21820156 -0.14810681 -0.5929734 ]\n",
      "[ 0.04381816  0.02542929 -0.15996629 -0.350365  ]\n",
      "[ 0.04432674  0.22242166 -0.16697359 -0.6889107 ]\n",
      "[ 0.04877517  0.02996213 -0.1807518  -0.4530989 ]\n",
      "[ 0.04937442  0.22711802 -0.18981378 -0.796867  ]\n",
      "[ 0.05391678  0.42426684 -0.20575112 -1.1427497 ]\n",
      "Episode finished after 19 timesteps\n",
      "[-0.04806443  0.02887696  0.01895853  0.04654879]\n",
      "[-0.04748689 -0.16651164  0.01988951  0.3451525 ]\n",
      "[-0.05081712  0.02832182  0.02679256  0.05880725]\n",
      "[-0.05025069 -0.16717383  0.0279687   0.35982156]\n",
      "[-0.05359416 -0.36268198  0.03516513  0.6611908 ]\n",
      "[-0.0608478  -0.55827516  0.04838895  0.96473557]\n",
      "[-0.0720133  -0.7540125   0.06768366  1.2722188 ]\n",
      "[-0.08709355 -0.94992983  0.09312804  1.5853057 ]\n",
      "[-0.10609215 -0.7560305   0.12483415  1.323057  ]\n",
      "[-0.12121277 -0.9524887   0.15129529  1.6520572 ]\n",
      "[-0.14026254 -0.75942314  0.18433644  1.4100784 ]\n",
      "Episode finished after 11 timesteps\n",
      "[ 0.03100042 -0.01324753  0.04903687 -0.02009713]\n",
      "[ 0.03073547  0.18113813  0.04863492 -0.29691407]\n",
      "[ 0.03435823  0.37553427  0.04269664 -0.5738704 ]\n",
      "[ 0.04186892  0.17984052  0.03121923 -0.26804835]\n",
      "[ 0.04546573 -0.01571275  0.02585827  0.03431558]\n",
      "[ 0.04515148  0.17902903  0.02654458 -0.25009793]\n",
      "[ 0.04873206  0.37376204  0.02154262 -0.5342914 ]\n",
      "[ 0.0562073   0.56857455  0.01085679 -0.82010925]\n",
      "[ 0.06757879  0.7635462  -0.00554539 -1.1093577 ]\n",
      "[ 0.08284971  0.5684976  -0.02773255 -0.81841964]\n",
      "[ 0.09421966  0.373766   -0.04410094 -0.53458685]\n",
      "[ 0.10169499  0.56947947 -0.05479268 -0.8408331 ]\n",
      "[ 0.11308458  0.7653049  -0.07160934 -1.1502315 ]\n",
      "[ 0.12839067  0.9612846  -0.09461397 -1.4644827 ]\n",
      "[ 0.14761636  1.1574296  -0.12390362 -1.7851593 ]\n",
      "[ 0.17076495  0.9638985  -0.15960681 -1.5334227 ]\n",
      "[ 0.19004293  0.77101874 -0.19027527 -1.2945058 ]\n",
      "Episode finished after 17 timesteps\n",
      "371.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "sumReward = 0\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        sumReward += reward\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()\n",
    "print(sumReward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4679f5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "738f8ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b8a216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d89e9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870152de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.1\n"
     ]
    }
   ],
   "source": [
    "# Q1.1\n",
    "\n",
    "# Runs a single episode and render it\n",
    "# Try running this before editing anything\n",
    "import gym\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    " # get initial state/observation\n",
    "sum = 0\n",
    "episodes = 20\n",
    "for i in range(20):\n",
    "    obs = env.reset() \n",
    "    sumReward = 0\n",
    "    while True:\n",
    "        # TODO: replace this `action` with something that depends on `obs` \n",
    "        if (obs[0] > 0) or (obs[2] > 0.2):\n",
    "            action = 0\n",
    "        elif (obs[0] < 0) or (obs[2] < -0.2):\n",
    "            action = 1\n",
    "        else: \n",
    "            action = env.action_space.sample()\n",
    "        #action = env.action_space.sample()  # random action\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        sumReward += reward\n",
    "        env.render()\n",
    "        #time.sleep(0.1)  # so it doesn't render too quickly\n",
    "        if done: break\n",
    "    env.close()\n",
    "    sum += sumReward\n",
    "print(sum/episodes)\n",
    "# TODO: print out your total sum of rewards here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32832b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get initial state/observation\n",
    "sum = 0\n",
    "episodes = 20\n",
    "for i in range(20):\n",
    "    obs = env.reset() \n",
    "    sumReward = 0\n",
    "    while True:\n",
    "        # TODO: replace this `action` with something that depends on `obs` \n",
    "\n",
    "        action = env.action_space.sample()  # random action\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        sumReward += reward\n",
    "        env.render()\n",
    "        #time.sleep(0.1)  # so it doesn't render too quickly\n",
    "        if done: break\n",
    "    env.close()\n",
    "    sum += sumReward\n",
    "print(sum/episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a665c19",
   "metadata": {},
   "source": [
    "\n",
    "1.2. [2pts] Describe the observation and action spaces of CartPole. What does each of the values mean/do? \n",
    "\n",
    "Observation: cart position, cart velocity, pole angle, pole angular velocity \\\n",
    "Action spaces: Discrete(2) \n",
    "\n",
    "1.3. [2pts] What distribution is used to sample initial states? (see the reset function) \n",
    "\n",
    "self.state = self.np_random.uniform(low=-0.05, high=0.05, size=(4,)) \\\n",
    "==> uniform distribution \n",
    "\n",
    "1.4. [2pts] What is the termination condition, which determines if the env is done? \\\n",
    "Termination condition: \\\n",
    "        Pole Angle is more than 12 degrees. \\\n",
    "        Cart Position is more than 2.4 (center of the cart reaches the edge of \\\n",
    "        the display). \\\n",
    "        Episode length is greater than 200. \n",
    "\n",
    "1.5. [2pts] Briefly describe your policy. What observation information does it use? What score did you achieve (rough maximum and average)? And how does it compare to the random policy? \\\n",
    "    Average score after 20 episodes: 33.85 compared to 22.15, slightly better \\\n",
    "    Policy: if the cart lies on one side, or if the pole leans too much on go to the other side, so that to balance the cart-pole in the middle and keep the episode as long as possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb731e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822997bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max = np.max(obs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8fce347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.1\n",
    "import gym\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "env = gym.make('CartPole-v0')\n",
    "def obs_normalizer(obs):\n",
    "    normed = copy.deepcopy(obs)\n",
    "    x_high, x_low = 4.8, -4.8\n",
    "    theta_high, theta_low = 48 * math.pi / 360, -48 * math.pi / 360\n",
    "    \n",
    "    # clip cart velocity and pole angular velocity to [-2,2]\n",
    "    normed[[1,3]] = np.clip(normed[[1,3]], -2, 2)\n",
    "    # normalize\n",
    "    normed[0] = (normed[0] - x_low) / (x_high - x_low)\n",
    "    normed[2] = (normed[2] - theta_low) / (theta_high - theta_low)\n",
    "    normed[[1,3]] = (normed[[1,3]] + 2) / 4\n",
    "    \n",
    "    return normed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1670b24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "### TEST 2.1\n",
    "def test_normed():\n",
    "    obs = env.reset()\n",
    "    while True:\n",
    "        obs, _, done, _ =  env.step(env.action_space.sample())\n",
    "        normed = obs_normalizer(obs) \n",
    "        assert np.all(normed >= 0.0) and np.all(normed <= 1.0), '{} are outside of (0,1)'.format(normed)\n",
    "        if done: break\n",
    "    env.close()\n",
    "    print('Passed!')\n",
    "test_normed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5c9340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.2\n",
    "\n",
    "def get_bins(normed, num_bins):\n",
    "    binned = np.minimum((normed * num_bins).astype(np.int32), num_bins - 1)\n",
    "    return binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514df790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-9d81bf46b032>:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  assert binned.dtype == np.int, \"You should also make sure to cast your answer to int using np.int() or arr.astype(np.int)\"\n"
     ]
    }
   ],
   "source": [
    "### TEST 2.2\n",
    "obs = env.reset()\n",
    "env.close()\n",
    "\n",
    "def test_binned(num_bins):\n",
    "    normed = np.array([0.0, 0.2, 0.8, 1.0])\n",
    "    binned = get_bins(normed, num_bins)\n",
    "    assert np.all(binned >= 0) and np.all(binned < num_bins), '{} supposed to be between (0, {})'.format(binned, num_bins-1)\n",
    "    assert binned.dtype == np.int, \"You should also make sure to cast your answer to int using np.int() or arr.astype(np.int)\" \n",
    "    \n",
    "test_binned(5)\n",
    "test_binned(10)\n",
    "test_binned(50)\n",
    "print('Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e70ddf",
   "metadata": {},
   "source": [
    "\n",
    "2.3. [2pts] If your state has 4 values and each is binned into N possible bins, how many bins are needed to represent all unique possible states)?\n",
    "\n",
    "4N\n",
    "\n",
    "2.4. [2pts] After discretizing state space, is the dynamics deterministic or non-deterministic? Explain your answer in one to two sentences.\n",
    "\n",
    "\n",
    "Deterministic, because the state would completely be determined after each action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a679fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Q Table:  (10, 10, 10, 10, 2)\n",
      "Original obs [ 0.0292154  -0.03600551  0.04987857  0.00212677] --> binned (5, 4, 5, 5)\n",
      "Value of Q Table at that obs/state value [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# hyper parameters. \n",
    "num_bins = 10\n",
    "alpha = 0.1\n",
    "gamma = 0.99\n",
    "log_n = 1000\n",
    "# epsilon greedy\n",
    "eps = 0.05  \n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "# Q-table initialized to zeros.  first 4 dims are state, last dim is for action (0,1) for left,right.\n",
    "Q = np.zeros([num_bins]*len(obs)+[env.action_space.n])\n",
    "# helper function to convert observation into a binned state so we can index into our Q-table\n",
    "obs2bin = lambda obs: tuple(get_bins(obs_normalizer(obs), num_bins=num_bins))\n",
    "\n",
    "s = obs2bin(obs)\n",
    "\n",
    "print('Shape of Q Table: ', Q.shape) # you can imagine why tabular learning does not scale very well\n",
    "print('Original obs {} --> binned {}'.format(obs, s))\n",
    "print('Value of Q Table at that obs/state value', Q[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d19cfb",
   "metadata": {},
   "source": [
    "Note: since Tabular Q learning is not scalable, Deep RL is a possible solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e84b7a94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At episode 0 the average return of the past 1000 iterations is 9.0\n",
      "At episode 1000 the average return of the past 1000 iterations is 9.645\n",
      "At episode 2000 the average return of the past 1000 iterations is 10.468\n",
      "At episode 3000 the average return of the past 1000 iterations is 10.439\n",
      "At episode 4000 the average return of the past 1000 iterations is 10.335\n",
      "At episode 5000 the average return of the past 1000 iterations is 10.405\n",
      "At episode 6000 the average return of the past 1000 iterations is 25.407\n",
      "At episode 7000 the average return of the past 1000 iterations is 82.246\n",
      "At episode 8000 the average return of the past 1000 iterations is 145.532\n",
      "At episode 9000 the average return of the past 1000 iterations is 165.129\n"
     ]
    }
   ],
   "source": [
    "# Q3.1\n",
    "def tabular_Q_learning(num_episodes = 20000, num_bins = 10, alpha = 0.1, \n",
    "                       gamma = 0.99, log_n = 1000, eps = 0.05, average_reward_goal = 150):\n",
    "    env = gym.make('CartPole-v0')\n",
    "    Q = np.zeros([num_bins]*len(env.reset())+[env.action_space.n])\n",
    "    rewardsEpisodes = []\n",
    "    for episode in range(num_episodes):\n",
    "        s = obs2bin(env.reset())\n",
    "        rewardsEpisodes.append(0)    \n",
    "        while True:\n",
    "            greedyAction = np.argmax(Q[s])\n",
    "            if np.random.rand() > eps:\n",
    "                action = greedyAction\n",
    "            else: \n",
    "                action = np.random.choice(2)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            o = obs2bin(obs)\n",
    "            Q[s][action] = Q[s][action] + alpha*(r+gamma*np.max(Q[o])-Q[s][action])\n",
    "            rewardsEpisodes[episode] += r\n",
    "            s = o\n",
    "            if done: break\n",
    "        if (episode%log_n == 0):\n",
    "            average_reward = np.mean(rewardsEpisodes[-log_n:])\n",
    "            print(\"At episode {} the average return of the past {} iterations is {}\".format(episode, log_n, average_reward))\n",
    "            if (average_reward_goal is not None) and (average_reward > average_reward_goal): break \n",
    "    env.close() \n",
    "    return Q, rewardsEpisodes\n",
    "_, _ = tabular_Q_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec3f813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At episode 0 the average return of the past 1000 iterations is 10.0\n",
      "At episode 1000 the average return of the past 1000 iterations is 9.844\n",
      "At episode 2000 the average return of the past 1000 iterations is 9.985\n",
      "At episode 3000 the average return of the past 1000 iterations is 10.084\n",
      "At episode 4000 the average return of the past 1000 iterations is 10.111\n",
      "At episode 5000 the average return of the past 1000 iterations is 10.034\n",
      "At episode 6000 the average return of the past 1000 iterations is 10.126\n",
      "At episode 7000 the average return of the past 1000 iterations is 10.022\n",
      "At episode 8000 the average return of the past 1000 iterations is 10.063\n",
      "At episode 9000 the average return of the past 1000 iterations is 10.03\n",
      "At episode 10000 the average return of the past 1000 iterations is 10.124\n",
      "At episode 11000 the average return of the past 1000 iterations is 10.122\n",
      "At episode 12000 the average return of the past 1000 iterations is 14.542\n",
      "At episode 13000 the average return of the past 1000 iterations is 53.444\n",
      "At episode 14000 the average return of the past 1000 iterations is 90.9\n",
      "At episode 15000 the average return of the past 1000 iterations is 149.407\n",
      "At episode 16000 the average return of the past 1000 iterations is 165.92\n",
      "At episode 17000 the average return of the past 1000 iterations is 168.793\n",
      "At episode 18000 the average return of the past 1000 iterations is 162.217\n",
      "At episode 19000 the average return of the past 1000 iterations is 169.557\n",
      "At episode 0 the average return of the past 1000 iterations is 11.0\n",
      "At episode 1000 the average return of the past 1000 iterations is 10.413\n",
      "At episode 2000 the average return of the past 1000 iterations is 10.464\n",
      "At episode 3000 the average return of the past 1000 iterations is 10.685\n",
      "At episode 4000 the average return of the past 1000 iterations is 29.918\n",
      "At episode 5000 the average return of the past 1000 iterations is 91.185\n",
      "At episode 6000 the average return of the past 1000 iterations is 155.623\n",
      "At episode 7000 the average return of the past 1000 iterations is 159.86\n",
      "At episode 8000 the average return of the past 1000 iterations is 174.228\n",
      "At episode 9000 the average return of the past 1000 iterations is 170.771\n",
      "At episode 10000 the average return of the past 1000 iterations is 165.691\n",
      "At episode 11000 the average return of the past 1000 iterations is 162.583\n",
      "At episode 12000 the average return of the past 1000 iterations is 164.366\n",
      "At episode 13000 the average return of the past 1000 iterations is 160.705\n",
      "At episode 14000 the average return of the past 1000 iterations is 150.408\n",
      "At episode 15000 the average return of the past 1000 iterations is 160.317\n",
      "At episode 16000 the average return of the past 1000 iterations is 167.623\n",
      "At episode 17000 the average return of the past 1000 iterations is 167.404\n",
      "At episode 18000 the average return of the past 1000 iterations is 154.44\n",
      "At episode 19000 the average return of the past 1000 iterations is 160.032\n",
      "At episode 0 the average return of the past 1000 iterations is 10.0\n",
      "At episode 1000 the average return of the past 1000 iterations is 11.215\n",
      "At episode 2000 the average return of the past 1000 iterations is 12.295\n",
      "At episode 3000 the average return of the past 1000 iterations is 12.052\n",
      "At episode 4000 the average return of the past 1000 iterations is 12.902\n",
      "At episode 5000 the average return of the past 1000 iterations is 12.452\n",
      "At episode 6000 the average return of the past 1000 iterations is 26.292\n",
      "At episode 7000 the average return of the past 1000 iterations is 33.176\n",
      "At episode 8000 the average return of the past 1000 iterations is 31.277\n",
      "At episode 9000 the average return of the past 1000 iterations is 120.628\n",
      "At episode 10000 the average return of the past 1000 iterations is 161.883\n",
      "At episode 11000 the average return of the past 1000 iterations is 156.262\n",
      "At episode 12000 the average return of the past 1000 iterations is 161.456\n",
      "At episode 13000 the average return of the past 1000 iterations is 158.715\n",
      "At episode 14000 the average return of the past 1000 iterations is 164.922\n",
      "At episode 15000 the average return of the past 1000 iterations is 168.718\n",
      "At episode 16000 the average return of the past 1000 iterations is 158.6\n",
      "At episode 17000 the average return of the past 1000 iterations is 154.896\n",
      "At episode 18000 the average return of the past 1000 iterations is 140.01\n",
      "At episode 19000 the average return of the past 1000 iterations is 150.072\n",
      "At episode 0 the average return of the past 1000 iterations is 9.0\n",
      "At episode 1000 the average return of the past 1000 iterations is 11.044\n",
      "At episode 2000 the average return of the past 1000 iterations is 11.262\n",
      "At episode 3000 the average return of the past 1000 iterations is 11.155\n",
      "At episode 4000 the average return of the past 1000 iterations is 11.35\n",
      "At episode 5000 the average return of the past 1000 iterations is 11.479\n",
      "At episode 6000 the average return of the past 1000 iterations is 11.386\n",
      "At episode 7000 the average return of the past 1000 iterations is 11.544\n",
      "At episode 8000 the average return of the past 1000 iterations is 11.445\n",
      "At episode 9000 the average return of the past 1000 iterations is 11.506\n",
      "At episode 10000 the average return of the past 1000 iterations is 11.419\n",
      "At episode 11000 the average return of the past 1000 iterations is 11.461\n",
      "At episode 12000 the average return of the past 1000 iterations is 12.058\n",
      "At episode 13000 the average return of the past 1000 iterations is 10.754\n",
      "At episode 14000 the average return of the past 1000 iterations is 10.606\n",
      "At episode 15000 the average return of the past 1000 iterations is 13.4\n",
      "At episode 16000 the average return of the past 1000 iterations is 46.528\n",
      "At episode 17000 the average return of the past 1000 iterations is 41.608\n",
      "At episode 18000 the average return of the past 1000 iterations is 44.134\n",
      "At episode 19000 the average return of the past 1000 iterations is 43.109\n",
      "At episode 0 the average return of the past 1000 iterations is 9.0\n",
      "At episode 1000 the average return of the past 1000 iterations is 9.905\n",
      "At episode 2000 the average return of the past 1000 iterations is 9.89\n",
      "At episode 3000 the average return of the past 1000 iterations is 9.859\n",
      "At episode 4000 the average return of the past 1000 iterations is 9.939\n",
      "At episode 5000 the average return of the past 1000 iterations is 36.48\n",
      "At episode 6000 the average return of the past 1000 iterations is 130.317\n",
      "At episode 7000 the average return of the past 1000 iterations is 153.889\n",
      "At episode 8000 the average return of the past 1000 iterations is 180.201\n",
      "At episode 9000 the average return of the past 1000 iterations is 181.477\n",
      "At episode 10000 the average return of the past 1000 iterations is 174.994\n",
      "At episode 11000 the average return of the past 1000 iterations is 166.929\n",
      "At episode 12000 the average return of the past 1000 iterations is 143.08\n",
      "At episode 13000 the average return of the past 1000 iterations is 144.351\n",
      "At episode 14000 the average return of the past 1000 iterations is 172.319\n",
      "At episode 15000 the average return of the past 1000 iterations is 156.246\n",
      "At episode 16000 the average return of the past 1000 iterations is 156.396\n",
      "At episode 17000 the average return of the past 1000 iterations is 152.571\n",
      "At episode 18000 the average return of the past 1000 iterations is 152.483\n",
      "At episode 19000 the average return of the past 1000 iterations is 160.762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x20aa73bb310>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from bottleneck import move_mean\n",
    "\n",
    "num_episodes = 20000\n",
    "\n",
    "min_returns = np.full(num_episodes, np.inf)\n",
    "max_returns = np.full(num_episodes, 0)\n",
    "mean_returns = np.full(num_episodes, 0)\n",
    "\n",
    "plt.close()\n",
    "for i in range(5):\n",
    "    _, returns = tabular_Q_learning(num_episodes=num_episodes, average_reward_goal=None)\n",
    "\n",
    "    min_returns = np.minimum(min_returns, returns)\n",
    "    max_returns = np.maximum(max_returns, returns)\n",
    "    mean_returns = mean_returns + np.array(returns)/5\n",
    "\n",
    "window_size = 100\n",
    "plt.plot(move_mean(mean_returns, window_size))\n",
    "plt.fill_between(np.arange(num_episodes),\n",
    "                move_mean(min_returns, window_size),\n",
    "                move_mean(max_returns, window_size),\n",
    "                alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b830d",
   "metadata": {},
   "source": [
    "\n",
    "4.2. [10pts] $\\epsilon$-greedy. How sensitive are the results to the value of $\\epsilon$? First, write down your prediction of what would happen if $\\epsilon$ is set to various values, including for example [0, 0.05, 0.25, 0.5].\n",
    "\n",
    "TODO: answer here\n",
    "\n",
    "Now run the experiment and observe the impact on the algorithm. Report the results below.\n",
    "\n",
    "Clearly epsilon makes significant differences (basic exploration/exploitation tradeoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "418ba0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At episode 0 the average return of the past 1000 iterations is 9.0\n",
      "At episode 1000 the average return of the past 1000 iterations is 9.364\n",
      "At episode 2000 the average return of the past 1000 iterations is 9.376\n",
      "At episode 3000 the average return of the past 1000 iterations is 9.373\n",
      "At episode 4000 the average return of the past 1000 iterations is 9.349\n",
      "At episode 5000 the average return of the past 1000 iterations is 9.361\n",
      "At episode 6000 the average return of the past 1000 iterations is 9.375\n",
      "At episode 7000 the average return of the past 1000 iterations is 9.352\n",
      "At episode 8000 the average return of the past 1000 iterations is 9.371\n",
      "At episode 9000 the average return of the past 1000 iterations is 9.343\n",
      "At episode 10000 the average return of the past 1000 iterations is 9.34\n",
      "At episode 11000 the average return of the past 1000 iterations is 9.362\n",
      "At episode 12000 the average return of the past 1000 iterations is 9.366\n",
      "At episode 13000 the average return of the past 1000 iterations is 9.376\n",
      "At episode 14000 the average return of the past 1000 iterations is 9.379\n",
      "At episode 15000 the average return of the past 1000 iterations is 9.335\n",
      "At episode 16000 the average return of the past 1000 iterations is 9.342\n",
      "At episode 17000 the average return of the past 1000 iterations is 9.398\n",
      "At episode 18000 the average return of the past 1000 iterations is 9.317\n",
      "At episode 19000 the average return of the past 1000 iterations is 9.34\n"
     ]
    }
   ],
   "source": [
    "_, _ = tabular_Q_learning(eps = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3064d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At episode 0 the average return of the past 1000 iterations is 9.0\n",
      "At episode 1000 the average return of the past 1000 iterations is 21.816\n",
      "At episode 2000 the average return of the past 1000 iterations is 84.053\n",
      "At episode 3000 the average return of the past 1000 iterations is 127.415\n",
      "At episode 4000 the average return of the past 1000 iterations is 147.043\n",
      "At episode 5000 the average return of the past 1000 iterations is 159.062\n"
     ]
    }
   ],
   "source": [
    "_, _ = tabular_Q_learning(eps = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67d9d624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At episode 0 the average return of the past 1000 iterations is 9.0\n",
      "At episode 1000 the average return of the past 1000 iterations is 58.369\n",
      "At episode 2000 the average return of the past 1000 iterations is 86.9\n",
      "At episode 3000 the average return of the past 1000 iterations is 89.396\n",
      "At episode 4000 the average return of the past 1000 iterations is 96.046\n",
      "At episode 5000 the average return of the past 1000 iterations is 97.596\n",
      "At episode 6000 the average return of the past 1000 iterations is 95.559\n",
      "At episode 7000 the average return of the past 1000 iterations is 96.506\n",
      "At episode 8000 the average return of the past 1000 iterations is 99.928\n",
      "At episode 9000 the average return of the past 1000 iterations is 97.565\n",
      "At episode 10000 the average return of the past 1000 iterations is 96.178\n",
      "At episode 11000 the average return of the past 1000 iterations is 92.739\n",
      "At episode 12000 the average return of the past 1000 iterations is 93.171\n",
      "At episode 13000 the average return of the past 1000 iterations is 90.489\n",
      "At episode 14000 the average return of the past 1000 iterations is 90.762\n",
      "At episode 15000 the average return of the past 1000 iterations is 86.987\n",
      "At episode 16000 the average return of the past 1000 iterations is 88.042\n",
      "At episode 17000 the average return of the past 1000 iterations is 89.754\n",
      "At episode 18000 the average return of the past 1000 iterations is 90.2\n",
      "At episode 19000 the average return of the past 1000 iterations is 85.854\n"
     ]
    }
   ],
   "source": [
    "_, _ = tabular_Q_learning(eps = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b80cb",
   "metadata": {},
   "source": [
    "Improve: use DQN to avoid overestimation/ positive bias. Use decay epsilon because when we nearly converge, don't need too much exploration, and also initialize Q randomly rather than 0. Moreover, since Q is not scalable as discussed above, if we want to scale, can consider policy gradnet of deep methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b05453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At episode 0 the average return of the past 1000 iterations is 20.0\n",
      "At episode 1000 the average return of the past 1000 iterations is 76.432\n",
      "At episode 2000 the average return of the past 1000 iterations is 151.256\n"
     ]
    }
   ],
   "source": [
    "def double_Q_learning(num_episodes = 20000, num_bins = 10, alpha = 0.1, \n",
    "                       gamma = 0.99, log_n = 1000, eps = 0.05, average_reward_goal = 150):\n",
    "    env = gym.make('CartPole-v0')\n",
    "    Q1 = np.random.sample([num_bins]*len(env.reset())+[env.action_space.n])\n",
    "    Q2 = np.random.sample([num_bins]*len(env.reset())+[env.action_space.n])\n",
    "    rewardsEpisodes = []\n",
    "    averages = []\n",
    "    for episode in range(num_episodes+1):\n",
    "        s = obs2bin(env.reset())\n",
    "        rewardsEpisodes.append(0)    \n",
    "        while True:\n",
    "            greedyAction = np.argmax(Q1[s]+Q2[s])\n",
    "            if np.random.rand() > eps:\n",
    "                action = greedyAction\n",
    "            else: \n",
    "                action = np.random.choice(2)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            next_o = obs2bin(obs)\n",
    "            if np.random.rand() > 0.5: \n",
    "                Q1[s][action] = Q1[s][action] + alpha*(r+Q2[next_o][np.argmax(Q1[next_o])]-Q1[s][action])\n",
    "            else: \n",
    "                Q2[s][action] = Q2[s][action] + alpha*(r+Q1[next_o][np.argmax(Q2[next_o])]-Q2[s][action])\n",
    "            rewardsEpisodes[episode] += r\n",
    "            s = next_o\n",
    "            if done: break\n",
    "        if (episode%log_n == 0):\n",
    "            average_reward = np.mean(rewardsEpisodes[-log_n:])\n",
    "            averages.append(average_reward)\n",
    "            print(\"At episode {} the average return of the past {} iterations is {}\".format(episode, log_n, average_reward))\n",
    "            if (average_reward_goal is not None) and (average_reward > average_reward_goal): break \n",
    "        eps = 1/(1+episode//100) #same idea with rate-decay learning, adam optimization\n",
    "    env.close() \n",
    "    return Q, rewardsEpisodes \n",
    "_, _ = double_Q_learning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8544850b",
   "metadata": {},
   "source": [
    "Yay, improved significantly "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
